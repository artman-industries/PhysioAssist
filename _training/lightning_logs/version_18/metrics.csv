train_loss,epoch,step
3199.549813726502,0,49
3409.054874734014,0,99
3720.547715987826,0,149
2968.8930233628494,0,199
3381.7715119536133,0,249
2997.9259872330445,0,299
2731.519694419391,0,349
3146.097969283588,0,399
3033.951927638898,0,449
2735.572288364692,0,499
2993.246843508446,0,549
2883.3140415270636,0,599
2232.8040593987726,0,649
2869.964534552826,0,699
3185.1175592069003,0,749
2803.653739632643,0,799
2479.19774265351,0,849
2694.1125128318263,0,899
3011.6881037383487,0,949
2781.9985754071017,0,999
2439.420304318447,1,1049
2635.7577643771956,1,1099
2912.684746662602,1,1149
2272.2515199867084,1,1199
2621.5599544172564,1,1249
2321.272973902428,1,1299
2107.9658771540826,1,1349
2462.8742141572766,1,1399
2389.0862733555314,1,1449
2132.0218710410145,1,1499
2336.772425775195,1,1549
2259.843827822972,1,1599
1715.218811264925,1,1649
2258.7722938514567,1,1699
2532.535213700919,1,1749
2203.9953052421456,1,1799
1939.802492141784,1,1849
2113.0060495982193,1,1899
2386.091647344548,1,1949
2204.1432005847378,1,1999
1912.4298813266325,2,2049
2093.720187582971,2,2099
2323.6749068855147,2,2149
1772.5840363232237,2,2199
2053.179516249678,2,2249
1818.7828193694747,2,2299
1650.6669510533313,2,2349
1946.0953477573748,2,2399
1903.896387573111,2,2449
1681.745001243256,2,2499
1835.7395821659327,2,2549
1786.7958284408137,2,2599
1337.5088121458177,2,2649
1793.2455771070154,2,2699
2027.231574914517,2,2749
1745.9964605012108,2,2799
1536.0860098606436,2,2849
1669.455865077017,2,2899
1900.0809685844492,2,2949
1761.1716799368482,2,2999
1515.5955492982707,3,3049
1681.8512660784238,3,3099
1867.1371513288423,3,3149
1398.1694777373225,3,3199
1614.0648440759558,3,3249
1440.13395913297,3,3299
1316.3285444846044,3,3349
1552.5326197787226,3,3399
1539.0181305910753,3,3449
1348.6946209256546,3,3499
1454.8239618271048,3,3549
1431.2432173448703,3,3599
1070.1147802710439,3,3649
1443.4053965661055,3,3699
1639.787583389613,3,3749
